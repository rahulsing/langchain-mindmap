<!DOCTYPE html>
<html>
  <head>
    <title>My Mind Map</title>
    <meta charset="UTF-8">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.css">
    <script src="https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js"></script>
  </head>
  <body>
    <div class="mermaid">
      mindmap
# LangChain API
    ## Prompt Management
        ### Prompt Templates
        ### Example Selectors
        ### Few-shot Prompting
    ## Model Invocation
        ### LLMs
            #### Examples
                ##### How to: cache model responses
                ##### How to: create a custom LLM class
                ##### How to: stream a response back
                ##### How to: track token usage
                ##### How to: work with local models
        ### Chat Models
            #### Integrations
                ##### Official models : langchain-<provider>
                ##### Community models : langchain-community
            #### methods
                ##### invoke
                ##### stream
                ##### batch
                ##### bind_tools
                ##### with_structured_output
            #### Inputs and outputs
                ##### LangChain Message Format
                ##### OpenAI's Message Format
            #### Examples
                ##### How to: do function/tool calling
                ##### How to: get models to return structured output
                ##### How to: cache model responses
                ##### How to: get log probabilities
                ##### How to: create a custom chat model class
                ##### How to: stream a response back
                ##### How to: track token usage
                ##### How to: track response metadata across providers
                ##### How to: use chat model to call tools
                ##### How to: stream tool calls
                ##### How to: handle rate limits
                ##### How to: few shot prompt tool behavior
                ##### How to: bind model-specific formatted tools
                ##### How to: force a specific tool call
                ##### How to: work with local models
                ##### How to: init any model in one line
        ### Messages
            #### SystemMessage
            #### HumanMessage
            #### AIMessage
            #### AIMessageChunk
            #### ToolMessage
            #### RemoveMessage
            #### (Legacy) FunctionMessage
            #### Examples
                ##### How to: trim messages
                ##### How to: filter messages
                ##### How to: merge consecutive messages of the same type
        ### Chat History
        ### Output Parsers
            #### Examples
                ##### How to: use output parsers to parse an LLM response into structured format
                ##### How to: parse JSON output
                ##### How to: parse XML output
                ##### How to: parse YAML output
                ##### How to: retry when output parsing errors occur
                ##### How to: try to fix errors in output parsing
                ##### How to: write a custom output parser class
        ### Structured Output
        ### Tool Calling
        ### Memory
            #### Example
                ##### How to: manage memory
                ##### How to: do retrieval
                ##### How to: use tools
                ##### How to: manage large chat history
        ### Multimodality
            #### Example
                ##### How to: pass multimodal data directly to models
                ##### How to: use multimodal prompts
    ## Data Management
        ### Document Loaders
            #### Examples
                ##### How to: load PDF files
                ##### How to: load web pages
                ##### How to: load CSV data
                ##### How to: load data from a directory
                ##### How to: load HTML data
                ##### How to: load JSON data
                ##### How to: load Markdown data
                ##### How to: load Microsoft Office data
                ##### How to: write a custom document loader
        ### Text Splitters
            #### Examples
                ##### How to: recursively split text
                ##### How to: split by HTML headers
                ##### How to: split by HTML sections
                ##### How to: split by character
                ##### How to: split code
                ##### How to: split Markdown by headers
                ##### How to: recursively split JSON
                ##### How to: split text into semantic chunks
                ##### How to: split by tokens
        ### Embedding Models
            #### Examples
                ##### How to: embed text data
                ##### How to: cache embedding results
        ### Vector Stores
            #### Example
                ##### How to: use a vector store to retrieve data
        ### Retrievers
            #### Examples
                ##### How to: use a vector store to retrieve data
                ##### How to: generate multiple queries to retrieve data for
                ##### How to: use contextual compression to compress the data retrieved
                ##### How to: write a custom retriever class
                ##### How to: add similarity scores to retriever results
                ##### How to: combine the results from multiple retrievers
                ##### How to: reorder retrieved results to mitigate the "lost in the middle" effect
                ##### How to: generate multiple embeddings per document
                ##### How to: retrieve the whole document for a chunk
                ##### How to: generate metadata filters
                ##### How to: create a time-weighted retriever
                ##### How to: use hybrid vector and keyword retrieval
        ### Retrieval
        ### Retrieval Augmented Generation (RAG)
            #### Example
                ##### How to: add chat history
                ##### How to: stream
                ##### How to: return sources
                ##### How to: return citations
                ##### How to: do per-user retrieval
    ## Task Execution
        ### Tools
            #### Example
                ##### How to: create tools
                ##### How to: use built-in tools and toolkits
                ##### How to: use chat models to call tools
                ##### How to: pass tool outputs to chat models
                ##### How to: pass run time values to tools
                ##### How to: add a human-in-the-loop for tools
                ##### How to: handle tool errors
                ##### How to: force models to call a tool
                ##### How to: disable parallel tool calling
                ##### How to: access the <code>RunnableConfig</code> from a tool
                ##### How to: stream events from a tool
                ##### How to: return artifacts from a tool
                ##### How to: convert Runnables to tools
                ##### How to: add ad-hoc tool calling capability to models
                ##### How to: pass in runtime secrets
        ### Agents
            #### Example
                ##### How to: use legacy LangChain Agents (AgentExecutor)
                ##### How to: migrate from legacy LangChain agents to LangGraph
        ### Runnable Interface
        ### LangChain Expression Language (LCEL)
    ## Callbacks
        ### Examples
            #### How to: pass in callbacks at runtime
            #### How to: attach callbacks to a module
            #### How to: pass callbacks into a module constructor
            #### How to: create custom callback handlers
            #### How to: use callbacks in async environments
            #### How to: dispatch custom callback events
    ## Tracing
    ## Evaluation
    ## Custom
        ### Example
            #### How to: create a custom chat model class
            #### How to: create a custom LLM class
            #### How to: write a custom retriever class
            #### How to: write a custom document loader
            #### How to: write a custom output parser class
            #### How to: create custom callback handlers
            #### How to: define a custom tool
            #### How to: dispatch custom callback events
    ## Serialization
        ### Examples
            #### How to: save and load LangChain objects
    ## Async Programming
    </div>
    <script>
      mermaid.initialize({ startOnLoad: true });
    </script>
  </body>
</html>
